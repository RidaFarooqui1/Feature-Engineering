{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* 1.What is a parameter?\n",
        "\n",
        "Ans->\n",
        "\n",
        "\n",
        "In Python, a parameter is a variable defined in the parentheses of a function's definition. It acts as a placeholder for the values that will be passed into the function when it is called. These values are known as argument"
      ],
      "metadata": {
        "id": "wTyZFIp9q1lC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2.What is correlation?\n",
        "What does negative correlation mean?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Correlation, in statistics, describes the relationship between two or more variables. A negative correlation means that as one variable increases, the other variable tends to decrease, and vice versa. Essentially, they move in opposite directions."
      ],
      "metadata": {
        "id": "CN0mZ_0mq1cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Machine learning (ML) is a subset of Artificial Intelligence (AI) that enables computer systems to learn from data and improve their performance on a specific task without being explicitly programmed for every detail. The main components in machine learning are: data, algorithms, models, and predictions."
      ],
      "metadata": {
        "id": "bJPuydCRq1T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4.How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Loss value is a crucial metric for evaluating a machine learning model's performance. It quantifies the difference between the model's predictions and the actual values, with smaller loss values indicating better predictions. By minimizing the loss during training, the model learns to generalize and make accurate predictions on unseen data."
      ],
      "metadata": {
        "id": "iz67lhOQq1Ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 5.What are continuous and categorical variables?\n",
        "\n",
        "Ans->\n",
        "\n",
        "In statistics, variables are classified as either continuous or categorical. Continuous variables represent measurements that can take on any value within a given range, while categorical variables represent categories or groups."
      ],
      "metadata": {
        "id": "TEkm4AYCq1D6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 6.How do we handle categorical variables in Machine Learning? What are the common t\n",
        "echniques?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Categorical variables, which represent qualitative data like colors or categories, need to be converted into a numerical format before being used in machine learning models. Common techniques include one-hot encoding, label encoding, ordinal encoding, and binary encoding."
      ],
      "metadata": {
        "id": "4NCD7HAPq08e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 7.What do you mean by training and testing a dataset?\n",
        "\n",
        "Ans->\n",
        "\n",
        "In machine learning, a dataset is split into training and testing sets. The training set is used to train the model, allowing it to learn patterns and relationships within the data. The testing set, which the model has not seen during training, is then used to evaluate the model's performance and accuracy on unseen data."
      ],
      "metadata": {
        "id": "cnB6mnAvq01C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 8.What is sklearn.preprocessing?\n",
        "\n",
        "Ans->\n",
        "\n",
        "sklearn.preprocessing is a module within the scikit-learn (sklearn) library in Python, dedicated to data preprocessing techniques. Data preprocessing is a crucial step in machine learning workflows, as it transforms raw data into a format more suitable for machine learning algorithms."
      ],
      "metadata": {
        "id": "Z8wzR2zJq0tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 9.What is a Test set?\n",
        "\n",
        "Ans->\n",
        "\n",
        "In machine learning, a test set is a portion of a dataset that is separate from the training and validation sets and is used to evaluate the performance of a trained machine learning model."
      ],
      "metadata": {
        "id": "QQXjx4Bgq0mK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 10.How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "Ans->\n",
        "\n",
        "To split data for model fitting in Python, the train_test_split function from the scikit-learn library is commonly used. This function divides the dataset into training and testing sets, typically using a ratio like 80/20 or 75/25, where the larger portion is used for training and the smaller for testing. A machine learning problem is approached by defining the problem, choosing a model, preparing the data, training the model, evaluating its performance, tuning parameters, and making predictions.\n"
      ],
      "metadata": {
        "id": "Cgth6WhKq0f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 11.Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Exploratory Data Analysis (EDA) should be performed before model fitting to understand the data's characteristics, identify potential issues, and guide the model selection and preparation process. EDA helps in cleaning the data, uncovering hidden patterns, detecting outliers, and assessing the suitability of different models."
      ],
      "metadata": {
        "id": "b6m9k90Uq0Vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 12.What is correlation?\n",
        "\n",
        "Ans->\n",
        "\n",
        "In machine learning, correlation refers to a statistical measure that describes the extent to which two or more variables change together. It quantifies the strength and direction of a linear relationship between variables. Correlation analysis is a fundamental tool in data exploration, feature selection, and understanding relationships within datasets."
      ],
      "metadata": {
        "id": "GWLk6Ob-q0PE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 13.What does negative correlation mean?\n",
        "\n",
        "Ans->\n",
        "\n",
        "A negative correlation, also known as an inverse correlation, means that two variables tend to move in opposite directions. When one variable increases, the other variable tends to decrease, and vice versa. This relationship does not necessarily imply causation; it simply describes a pattern where the variables tend to move apart from each other.\n"
      ],
      "metadata": {
        "id": "WIJ1-WxRq0IM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 14.What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Ans->\n",
        "\n",
        "To find the correlation between variables in Python, you can use the pandas library. The .corr() method calculates the correlation matrix, showing the correlation coefficient between all pairs of numeric columns in a DataFrame. For a more in-depth analysis, you can also use the scipy.stats.pearsonr() function to get the Pearson correlation coefficient and p-value for a specific pair of variables.\n"
      ],
      "metadata": {
        "id": "2D8kUPCnq0CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 15.What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Ans->\n",
        "\n",
        "Causation means that one event directly causes another, while correlation indicates a relationship between two events where they tend to occur together, but one doesn't necessarily cause the other. A key difference is that causation implies a cause-and-effect relationship, while correlation simply shows an association."
      ],
      "metadata": {
        "id": "J6WBqHT5qz7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "Ans->\n",
        "\n",
        "In machine learning, an optimizer is an algorithm that adjusts the parameters (weights and biases) of a neural network to minimize the loss function."
      ],
      "metadata": {
        "id": "31sWBw5eqz1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 17.What is sklearn.linear_model ?\n",
        "\n",
        "Ans->\n",
        "\n",
        "sklearn.linear_model is a sub-module within the scikit-learn (sklearn) library in Python, dedicated to implementing various linear models for both regression and classification tasks.\n"
      ],
      "metadata": {
        "id": "fPOp0c5pqzuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 18.What does model.fit() do? What arguments must be given?\n",
        "\n",
        "Ans->\n",
        "\n",
        "The model.fit() method in machine learning libraries like TensorFlow/Keras and Scikit-learn is used to train a machine learning model. This process involves adjusting the internal parameters (weights and biases in neural networks, or coefficients in linear models) of the model to learn patterns from the provided training data. The goal is to minimize a defined loss function, which measures the discrepancy between the model's predictions and the actual target values."
      ],
      "metadata": {
        "id": "5Ru3k5k6qznA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 19.What does model.predict() do? What arguments must be given?\n",
        "\n",
        "Ans->\n",
        "Purpose : model. predict() is used to generate predictions from the trained model based on new input data. It does not require true labels and does not compute any metrics."
      ],
      "metadata": {
        "id": "X_R7GdHqqzfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 20.What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Ans->\n",
        "\n",
        "In statistics, variables are classified as either continuous or categorical. Continuous variables represent measurements that can take on any value within a given range, while categorical variables represent categories or groups."
      ],
      "metadata": {
        "id": "V7w-wXKiqzWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 21.What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Feature scaling is a data preprocessing technique that transforms the numerical features of a dataset to a similar scale. This process is crucial in machine learning because it prevents features with larger values from disproportionately influencing the model, leading to more accurate and efficient learning. Essentially, it ensures all features contribute equally to the model's calculations, regardless of their original units or magnitudes.\n"
      ],
      "metadata": {
        "id": "EvTkAWEEqx52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 22.How do we perform scaling in Python?\n",
        "\n",
        "ANs->\n",
        "\n",
        "Scaling data in Python is typically performed using the scikit-learn library's preprocessing module, which offers various scalers like StandardScaler and MinMaxScaler."
      ],
      "metadata": {
        "id": "1J5c6m5BqxwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 23.What is sklearn.preprocessing?\n",
        "\n",
        "Ans->\n",
        "\n",
        "The sklearn.preprocessing module within the scikit-learn library in Python provides a collection of utility functions and transformer classes designed to prepare raw feature vectors for use with machine learning estimators. This preparation, known as data preprocessing, is a crucial step in the machine learning workflow."
      ],
      "metadata": {
        "id": "Q_gwlCZeqxhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 24.How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "Ans->\n",
        "\n",
        "To split data for model fitting, training, and testing in Python, the train_test_split function from the sklearn.model_selection module is commonly used. This function divides the dataset into a training set (used to train the model) and a testing set (used to evaluate the trained model's performance on unseen data)."
      ],
      "metadata": {
        "id": "-5T-yuW9qxW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 25.Explain data encoding?\n",
        "\n",
        "Ans->\n",
        "\n",
        "Data encoding is the process of converting data into a specific format for efficient storage, transmission, or processing. It's essentially transforming data into a form that a computer or system can understand and work with, often involving representing information in a numerical or standardized format."
      ],
      "metadata": {
        "id": "UagLVd1eqxIS"
      }
    }
  ]
}